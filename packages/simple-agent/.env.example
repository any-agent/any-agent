# LLM Provider Configuration
# Options: "anthropic", "openai", "openai-compatible"
AI_PROVIDER=anthropic

# Anthropic (Claude) Configuration
ANTHROPIC_API_KEY=your_anthropic_key_here
AI_MODEL=claude-3-5-sonnet-20241022

# OpenAI (GPT) Configuration (uncomment if using OpenAI)
# AI_PROVIDER=openai
# OPENAI_API_KEY=your_openai_key_here
# AI_MODEL=gpt-4o

# LM Studio / Local Models Configuration (uncomment if using LM Studio or other OpenAI-compatible API)
# AI_PROVIDER=openai-compatible
# OPENAI_BASE_URL=http://localhost:1234/v1  # LM Studio default URL
# AI_MODEL=your-model-name  # The model name/ID from LM Studio
# OPENAI_API_KEY=not-needed  # Optional, LM Studio doesn't require a real key

# Ollama Configuration (uncomment if using Ollama)
# AI_PROVIDER=openai-compatible
# OPENAI_BASE_URL=http://localhost:11434/v1  # Ollama with OpenAI compatibility
# AI_MODEL=llama3.2
# OPENAI_API_KEY=ollama

# Tools Supervisor URL
SUPERVISOR_URL=http://localhost:8080
